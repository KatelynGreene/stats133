---
title: "USCountyUrbanForestData"
author: "Team Senioritis"
date: "4/21/17"
output: 
  html_document:
    fig_height: 3
    fig_width: 5 
---
<!-- Don't edit in between this line and the one below -->
```{r include=FALSE}
# Don't delete this chunk if you are using the DataComputing package
library(DataComputing) 
library(XML)
library(RCurl)
library(readxl)
```
*Source file* 
```{r, results='asis', echo=FALSE}
includeSourceDocuments()
```
<!-- Don't edit the material above this line -->

The purpose of this document is to extract urban forest from all the counties in the U.S.
The original data source is:
https://www.nrs.fs.fed.us/data/urban/ 

Extracts the links to each State from the main link:
https://www.nrs.fs.fed.us/data/urban/
```{r}
URL <- "https://www.nrs.fs.fed.us/data/urban/"
txt <- getURLContent(URL)
doc <- htmlParse(txt)

#Scrape the county name
stateNames <- xpathSApply(doc, '//ul/li/a/strong', xmlValue)

#****NOTE: Missing Alaska and Hawaii*******
stateLinks <- xpathSApply(doc, '//ul[@class="state_list"]/li/a/@href')
baseURL <- "https://www.nrs.fs.fed.us"
stateLinks <- paste(baseURL,as.character(stateLinks),sep="")

#Data Frame of StateName and stateLink
AllStates <- data.frame(stateNames, stateLinks, stringsAsFactors = FALSE)
head(AllStates) 
```

Extracts the excel file download link for each state
```{r}
downloadLinks <- vector(mode="character", length=length(AllStates$stateNames))

for (i in 1:length(stateLinks)){
  stateURL<- stateLinks[i]
  stateTxt <- getURLContent(stateURL)
  stateDoc <- htmlParse(stateTxt)
  downloadLink <- xpathSApply(stateDoc, '//ol[@id="data_options"]/li/a/@href')

  #The HTML source code is poor so need to use grepl to extract .xls from Xpath results
  length(downloadLink)
  for (j in 1:length(downloadLink)){
     if (grepl(".xls", downloadLink[j])){
      downloadLinks[i] <- downloadLink[j]
      break 
    }
  }
}

AllStates$downloadLinks <- downloadLinks

AllStates$downloadLinks
 
```

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Downloading and loading Excel files (Method 1: Using Tempfiles)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
```{r}
#for(i in 1:1){ #length(AllStates$downloadLinks)){
  #Download xls file
  url <- AllStates$downloadLinks[1]
  tmp <- tempfile(fileext=".xls")
  download.file(url,destfile=tmp, mode="wb")
  
```

```{r}
  
  #Read-in relevant sheets (7 and 10)
  xl_7 <- read_excel(tmp, sheet = 7, skip = 3)
  xl_10 <- read_excel(tmp, sheet = 10, skip = 3)
  
  #Clean and select relevant variables
  
  #head(xl_7)
  xl_7 <- xl_7 %>% select(c(`X__1`, `m2/person__1`, `Available green space (ha)`))
  #Units: Tree canopy Covering (m2/person), Available green space (ha)
  colnames(xl_7) <- c("CountyName","TreeCanopy", "AvailGreenSpace")
  
  #summary(xl_7)
  head(xl_7)
  
  xl_10 <- xl_10 %>% select(c(`X__1`, `Tree % h`))
  #Tree canopy cover in developped regions (%)
  colnames(xl_10) <- c("CountyName", "TreeCanopyCover")
  #head(xl_10)
  
  #Exclude the variable descriptions at the end of the sheet
  xl_10 <- na.omit(xl_10)
  head(xl_10)
  #summary(xl_10)
  
  #Join the two sheets
  joined <- full_join(xl_7, xl_10, by = "CountyName")
  View(joined)
  
  joined_clean <- joined %>% subset(CountyName != "Statewide")
  
  View(joined_clean)
  #unlink(tmp)
#}




#names(df)[names(df) == 'old.var.name'] <- 'new.var.name'
  
```





Download each excel file, load it into R as a dataframe, and assign the data frame to the respective state name.
NOTE THE DOWNLOAD TIME IS ENORMOUS!!! DON'T RUN THIS ON ALL STATES YET, IT CRASHES EVERYTHING.
```{r}
library(readxl)
for(i in 1:1){ #length(AllStates$stateNames)){
  destination <- paste("C:\\Users\\Katrlyn\\Downloads\\", AllStates$stateNames[i], ".xls", sep = "")
  #Works but the issue is that file must be handled locally during preprocessing.
  download.file(AllStates$downloadLinks[i], destfile = destination, mode = "wb" )

  test <- read_excel(destination, sheet = 10, skip = 3)
  
  assign(AllStates$stateNames[i], test)
  
}
```

Accessing the stored tables
```{r}
head(Alabama)

#Accessing names:
#as.name(countyName[1])

```



#'/Users/anishakumar/Desktop'
  

#this works '//div[@id="bio"]/p'
#'//div[@id="bio"]/p/ol[@id = "data_options"]/li/a'
```
for (j in 1:length(stateExcel)){
    if grepl( "xls$", stateExcel[j]){ 
      stateExcel <- stateExcel[j]
      break
    }
  }

