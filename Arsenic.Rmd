---
title: "Arsenic interpolation"
author: ""
date: ""
output: 
  html_document:
    fig_height: 3
    fig_width: 5
---
<!-- Don't edit in between this line and the one below -->
```{r include=FALSE}
# general packages you need to run the code
library(DataComputing)
library(ggplot2)
library(dplyr)
library(tidyr)
library(XML)
library(readxl)
library(lubridate)

# geospatial analysis tools needed to run maps and interpolations
library(gstat)
library(sp)
library(maptools)
library(spatstat)
```
*Source file* 
```{r, results='asis', echo=FALSE}
includeSourceDocuments()
```
<!-- Don't edit the material above this line -->


## Arsenic data
```{r}
## DOWNLOAD FILE
## downloads arsenic excel file into temp file without permanently downloading onto the computer
url <- "https://water.usgs.gov/nawqa/trace/data/arsenic_nov2001.xls"
tmp <- tempfile(fileext=".xls")
download.file(url,destfile=tmp, mode="wb")
arsenic <- read_excel(tmp, skip=58)

## DATA CLEANING
## get rid of non-continental US data (Alaska, Puerto Rico, Virgin Islands)
arsenic <- arsenic[!arsenic$STATE %in% c("AK","PR","VI"),]
## only keep columns we need (especially becuase a few of the unnecessary columns loaded in really weird)
## columns needed: state, fips code, arsenic concentration, latitude & longitude
arsenic <- arsenic %>%
  dplyr::select(STATE,FIPS,AS_CONC,LAT_DD,LON_DD)
## many numeric data is in character form--change from character to numeric
## you can see the data form for all columns using:
## str(arsenic)
arsenic$LAT_DD <- as.numeric(arsenic$LAT_DD)
arsenic$LON_DD <- as.numeric(arsenic$LON_DD)
arsenic$AS_CONC <- as.numeric(arsenic$AS_CONC)
arsenic$FIPS <- as.numeric(arsenic$FIPS)
## take out any observations with incomplete data (eg. missing fips or arsenic)
arsenic <- arsenic[complete.cases(arsenic[,2]),]

```

## US county map
```{r}
## bring in map of all counties from Katelyn's code: ggplotMapsTEST.Rmd
library(tigris)
us.map <- tigris::counties(cb = TRUE, year = 2015)
us.map <- us.map[!us.map$STATEFP %in% c("02", "15", "72", "66", "78", "60", "69",
                                        "64", "68", "70", "74"),]
us.map <- us.map[!us.map$STATEFP %in% c("81", "84", "86", "87", "89", "71", "76",
                                        "95", "79"),]
library(broom)
county_map <- tidy(us.map, region="GEOID")
###END of map code

## you can see what the arsenic data looks like on the US map
ggplot() +
  geom_polygon(data= county_map, aes(x=long, y=lat, group=group), fill = "white", color="black", size=0.25) +
  geom_point(data=arsenic, aes(x=-LON_DD, y=LAT_DD, col=AS_CONC))

```

## Interpolation of arsenic data

The reason we need to interpolate the arsenic data is because we only have point data from the field stations that take arsenic measurements. This doesn't cover every county in the US. In order to create a continuous data of arsesnic concentrations across the US, we do a spatial interpolation that essentially takes the point arsenic concentrations and estimates the arsenic concentration across the entire area using a geospatial statistical model. In this case, the units of interpolation are 0.1 degree longitude by 0.1 degree latitude (roughly 0.25 sq mi), which means we get an arsenic concentration for every 0.25 sq mi area of the US. Then we calculate the average arsenic concentration for each county. This way we get an estimated arsenic concentration for each county.
```{r}
## PREPPIND DATA FOR INTERPOLATION
## duplicate cleaned arsenic data to prevent overwriting
arsenic_test <- arsenic
## assign coordinates--LON must be multiplied by negative to reflect that it is located in the W. Hemisphere
## if not, this will plot on a mirrored image of the US
arsenic_test$x <- -1*arsenic_test$LON_DD
arsenic_test$y <- arsenic_test$LAT_DD

## this makes arsenic_test into a spatial data
coordinates(arsenic_test) = ~x + y
plot(arsenic_test)
## define the projection for arsenic_test to match the projection for us.map
proj4string(arsenic_test) <- proj4string(us.map)

## setting the interpolation area
## basically the 4 most outer points of us.map in terms of longitude and latitude
## you can check this using:
summary(us.map)  ## see coordinates min & max
x.range <- as.numeric(c(-125, -66))  # min/max longitude of the interpolation area
y.range <- as.numeric(c(24, 50))  # min/max latitude of the interpolation area

## this creates the interpolation grid
## it specifies the interpolatino area, and the resolution--in this case 0.1 deg. lon. x 0.1 deg. lat.
grd <- expand.grid(x = seq(from = x.range[1], to = x.range[2], by = 0.1), y = seq(from = y.range[1], to = y.range[2], by = 0.1))
coordinates(grd) <- ~x + y # define spatial coordinates of grd
proj4string(grd) <- proj4string(us.map) #with the same projections
gridded(grd) <- TRUE

## visualization of grid and arsenic data
plot(grd, cex = 1.5, col = "grey")
points(arsenic_test, pch = 1, col = "red", cex = 1)

## perform the interpolation! (this will take ~20min)
idw <- krige(AS_CONC ~ 1, arsenic_test, grd)
idw.out = as.data.frame(idw)
names(idw.out)[1:3] <- c("long", "lat", "arsenic_pred")


## here's what the interpolation looks like with the us.map
ggplot() +
  geom_tile(data = idw.out, alpha = 0.8, aes(x = long, y = lat, fill = round(arsenic_pred, 0)))  +
  scale_fill_gradient(low = "cyan", high = "orange") + 
  geom_polygon(data= county_map, aes(x=long, y=lat, group=group), fill = NA, color="black", size=0.25) +
  geom_point(data=arsenic, aes(x=-LON_DD, y=LAT_DD), color="red")

```


## Summarizing the interpolated data

Now we have arsenic values for every ~0.25 sq mi of the US. Next we want to find the average arsenic concentration per county.
```{r}
library(raster)

## convert results of interpolation from spatial pixel data to spatial raster data
idw_raster <- raster(idw)
## take the mean raster value (= arsenic concentrations) within the bounds of each county defined by us.map
avgArsenic <- extract(idw_raster, us.map, fun = mean, sp=TRUE)
## convert results to data frame for data manipulation
avgArsenic_df <- as.data.frame(avgArsenic)
save(avgArsenic_df, file = "avgArsenic_df.RData")

load("avgArsenic_df.RData")

## join arsenic info to county_map using identital fips for easy plotting
county_map_As <- left_join(county_map, avgArsenic_df, by = c("id" = "GEOID"))

ggplot() +
    #blank county map
    geom_polygon(data= county_map_As, aes(x=long, y=lat, group=group), fill = "white", color="black", size=0.25) +
    #Arsenic data
    geom_polygon(data= county_map_As, aes(x=long, y=lat, group=group, fill = var1.pred), color="black", size=0.25) +
    ggplot2::coord_map() +
    scale_fill_gradientn(colors = c("green", "red"))  +
    labs(title="Arsenic Levels") + 
    theme_bw() +
    theme(axis.line=element_blank(),
          axis.text.x=element_blank(),
          axis.text.y=element_blank(),
          axis.ticks=element_blank(),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank(),
          legend.title=element_blank())

```


## The only data we actuallly need is here:
```{r}
arsenic_df <- avgArsenic_df %>%
  dplyr::select(GEOID, var1.pred)
names(arsenic_df) <- c("fips","arsenic")

```


## Combine with education & income data

```{r}
GetEduData <- function(){
  
  #Download and read data
  url <- "https://www.ers.usda.gov/webdocs/DataFiles/CountyLevel_Data_Sets_Download_Data__18026/Education.xls?v=42762"
  tmp <- tempfile(fileext=".xls")
  download.file(url, destfile=tmp, mode="wb")
  edu_data_unclean <- read_excel(tmp, sheet = 1, skip = 4)
  
  unlink(tmp)
  
  #Wrangle and select variables
  edu_data<-edu_data_unclean[, grep("2011|FIPS Code|2013 Urban", colnames(edu_data_unclean))]
  edu_data<-edu_data[, grep("Percent|FIPS Code|2013 Urban", colnames(edu_data))]
  edu_data<-edu_data%>%dplyr::rename(FIPSCode=`FIPS Code`)
  colnames(edu_data)<-c('FIPSCode', 'UrbanCode', 'LessThanHS', 'HSDiploma', 'SomeCollege','Bachelors')
  
  return(edu_data)
}

edu_data <- GetEduData()

GetIncomeData <- function(){
  
  #download/clean USACountyIncomeEmploy data
  url <- "https://www.ers.usda.gov/webdocs/DataFiles/CountyLevel_Data_Sets_Download_Data__18026/Unemployment.xls?v=42762"
  tmp <- tempfile(fileext=".xls")
  download.file(url, destfile=tmp, mode="wb")
    
  income_unclean <- read_excel(tmp, sheet = 1, skip = 7)
  
  unlink(tmp)
  
  income <- income_unclean %>% 
    mutate(Area_name= gsub(", ..$", "", Area_name), Area_name)%>%
    subset(select=c("FIPStxt","Median_Household_Income_2015","Unemployment_rate_2015"))%>%
    dplyr::rename(FIPSCode=FIPStxt)
  
  colnames(income) <- c("FIPSCode", "Income", "Unemployment")
  income$IncomeQuartile <- ntile(income$Income, 4)
  income$IncomeQuartile[income$IncomeQuartile == 1] <- "< $40k"
  income$IncomeQuartile[income$IncomeQuartile == 2] <- "$40k - 47k"
  income$IncomeQuartile[income$IncomeQuartile == 3] <- "$47k - 54k"
  income$IncomeQuartile[income$IncomeQuartile == 4] <- "> $54k"
  income$IncomeQuartile <- base::as.factor(income$IncomeQuartile)
  income$IncomeQuartile = factor(income$IncomeQuartile, levels(income$IncomeQuartile) [c(3,1,2,4)])
  return(income)
}

income <- GetIncomeData()


GetPollutionData <- function(){
  #dowload/wrangle the PollutionPerCounty data
  poll_county_unclean<-read.csv("https://data.cdc.gov/api/views/cjae-szjv/rows.csv?accessType=DOWNLOAD")
  poll_county<-poll_county_unclean %>%
    filter(MeasureType=='Average')%>%
    group_by(ReportYear)%>%
    arrange(CountyName)%>%
    arrange(StateName)%>%
    filter(MeasureId==296)%>%
    dplyr::rename(FIPSCode=CountyFips)%>%
    subset(select=c(FIPSCode, ReportYear, Value, Unit))%>%
    mutate(FIPSCode=gsub("46113","46102", FIPSCode))%>%
    filter(ReportYear==2010)%>%
    subset(select=-c(ReportYear))
  poll_county$FIPSCode<-stri_pad_left(poll_county$FIPSCode, 5, "0")  
  
  colnames(poll_county) <- c("FIPSCode", "Pollution", "Unit")
  
  return(poll_county)
}
 pollution <- GetPollutionData()

 
all_data_arsenic <- all_data %>%
  left_join(arsenic_df, by = c("FIPSCode" = "fips"))

all_data_arsenic$coll_HS[all_data_arsenic$coll_HS >= 5] <- NA
all_data_arsenic$arsenic[all_data_arsenic$arsenic > 100] <- NA
all_data_arsenic$State <- as.factor(all_data_arsenic$State)
all_data_arsenic$StateFips <- as.factor(all_data_arsenic$FIPSCode)
all_data_arsenic$UrbanCode <- as.factor(all_data_arsenic$UrbanCode)
  
```

## Boxplots for air pollution, arsenic, and tree cover
```{r}

air_edu_boxplot <- all_data_arsenic %>%
  ggplot(aes(Pollution, Bachelors)) +
  geom_boxplot(aes(color = UrbanCode), size = 1) +
  geom_point(aes(color = UrbanCode), alpha = 0.3, size = 2) +
  #scale_color_manual(values = c("#6baed6","#4292c6","#2171b5","#084594")) +
  geom_smooth(method = "lm") +
  #facet_grid( ~ IncomeQuartile) +
  facet_grid(~ UrbanCode)
  labs(x="Concentration of PM 2.5 (ug/m^3)", y="% Adults with Bachelor's Degrees") +
  theme_bw()


as_edu_boxplot <- all_data_arsenic %>%
  ggplot(aes(arsenic, Bachelors)) +
  geom_boxplot(aes(color = IncomeQuartile), size = 1) +
  geom_point(aes(color = IncomeQuartile), alpha = 0.3, size = 2) +
  scale_color_manual(values = c("#6baed6","#4292c6","#2171b5","#084594")) +
  geom_smooth(method = "lm") +
  facet_grid( ~ IncomeQuartile) +
  labs(x="Concentration of Arsenic (ug/L)", y="% Adults with Bachelor's Degrees") +
  theme_bw()

tree_edu_boxplot <- all_data_arsenic %>%
  ggplot(aes(TreeCanopyCover, Bachelors)) +
  geom_boxplot(aes(color = IncomeQuartile),size = 1) +
  geom_point(aes(color = IncomeQuartile), alpha = 0.3, size = 2) +
  scale_color_manual(values = c("#6baed6","#4292c6","#2171b5","#084594")) +
  geom_smooth(method = "lm") +
  facet_grid( ~ IncomeQuartile) +
  labs(x="% Tree Canopy Cover", y="% Adults with Bachelor's Degrees") +
  theme_bw()

air_edu_boxplot
as_edu_boxplot
tree_edu_boxplot


```
