---
title: "JoinAllTables"
author: "Vanessa"
date: ""
output: 
  html_document:
    fig_height: 3
    fig_width: 5
---
<!-- Don't edit in between this line and the one below -->
```{r include=FALSE}
# Don't delete this chunk if you are using the DataComputing package
library(DataComputing)
library(RCurl)
library(readxl)
library(mosaic)
library(readr)
library(tidyr) 
library(dplyr)
library(stringi)
library(XML)
library(rvest)
library(rgdal)
```
*Source file* 
```{r, results='asis', echo=FALSE}
includeSourceDocuments()
```
<!-- Don't edit the material above this line -->


#' Scrapes the excel download link for each state in the U.S.
#' Source: https://www.nrs.fs.fed.us/data/urban/
#'
#' @param x A number
#' @param y A number
#' @return The sum of \code{x} and \code{y}

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Downloading the USACountyEduAttainment data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
```{r}
#' @Variables of interest: UrbanRank (Anisha is currently  making it) and Bachelors (%) 
#' @Year 2013 Rural-Urban Continuum Codes, 2011-2015 Education Attainment

#' Scrapes the excel download link for US County Education Attainment
#' Source: "https://www.ers.usda.gov/data-products/county-level-data-sets/county-level-data-sets-download-data.aspx" and click Educational attainment for the U.S., States, and counties, 1970-2015
#'
#' @return The edu_data that contains the FIPSCode, UrbanCode (2013 Rural-Urban Continuum Code), LessThanHS (%), HSDiploma (%), Bachelors (%), UrbanRank. 

GetEduData <- function(userName){
  
  # #Use downoload link to read the data
  # url <- "https://www.ers.usda.gov/webdocs/DataFiles/CountyLevel_Data_Sets_Download_Data__18026/Education.xls?v=42762"
  # #tmp is a temporary file in which the data from the excel sheet is stored 
  # tmp <- tempfile(fileext=".xls")
  # download.file(url, destfile=tmp, mode="wb")
  # #read data from sheet 1 beginning at row 5
  # edu_data_unclean <- read_excel(tmp, sheet = 1, skip = 4)
  # 
  # #Get rid of the temporary file tmp
  # unlink(tmp)
  
  #------------------
  # Local Download (USDA down)
  # ----------------
  # ----------------
  if(userName == "K"){
    path <- "C:\\Users\\kanay\\Documents\\R\\stat133\\AllStates\\"
  }else if(userName == "V"){
    path <- "~/Downloads/stats133data"
  }else if(userName == "A") {
    path <- "/Users/anishakumar/Documents/Stats133/RStudioFiles/Stats133Project/edu.xls"
  }else if(userName == "KS"){
    path <- "C:\\Users\\kagex\\Downloads\\edu.xls"
  }else{
    path <- "C:\\Users\\Katrlyn\\Downloads\\edu.xls"
  }
  edu_data_unclean <- read_excel(path, sheet = 1, skip = 4)
  
  
  #Wrangle and select variables
  
  #Choose the columns from edu_data_clean that has FIPS Code, 2013 Rural-Urban Continuum Code and any columns that have information from 2011
  edu_data<-edu_data_unclean[, grep("2011|FIPS Code|2013 Rural", colnames(edu_data_unclean))] 
  
  #Choose columns from edu_data taht has FIPSCode, 2013 Rural-Urban Continuum Code and Percent
  edu_data<-edu_data[, grep("Percent|FIPS Code|2013 Rural", colnames(edu_data))]
  
  #Rename FIPS Code column to FIPSCode
  edu_data<-edu_data%>%dplyr::rename(FIPSCode=`FIPS Code`)
  
  #Rename the columns so that they are cleaner 
  colnames(edu_data)<-c('FIPSCode', 'UrbanCode', 'LessThanHS', 'HSDiploma', 'SomeCollege','Bachelors')
  
  edu_data$UrbanRank <- ""
  
  #The for loop classifies the UrbanCode (Rural-Urban Continuum Code). 1-3 is metropolitan, 4-7 is urban and 8 - 11 is rural. s
  for (i in 1:nrow(edu_data)){
     if (is.na(edu_data$UrbanCode[i])){
       edu_data$UrbanRank[i] <- NA
      } else if (edu_data$UrbanCode[i] <= 3){
        edu_data$UrbanRank[i] <- "Metropolitan"
      } else if (edu_data$UrbanCode[i] <= 7){
        edu_data$UrbanRank[i] <- "Urban"
      } else {
        edu_data$UrbanRank[i] <- "Rural"
      }
  }
  edu_data$UrbanRank <- factor(edu_data$UrbanRank, levels = c("Rural", "Urban", "Metropolitan"))
  return(edu_data)
}


```

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Downloading the Pollution per County data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r}
#' Downloads and wrangles pollution data in the form of air quality measurements from the EPA. 
#' Source: https://data.cdc.gov/dataset/Air-Quality-Measures-on-the-National-Environmental/cjae-szjv
#' @Variables: Annual average ambient concentrations of PM2.5 in micrograms per cubic meter 
#' (based on seasonal averages and daily measurement)
#' @Year: 2010
#'
#' @return data frame containing air quality for each county in the united states

GetPollutionData <- function(){
  poll_county_unclean<-read.csv("https://data.cdc.gov/api/views/cjae-szjv/rows.csv?accessType=DOWNLOAD")
  poll_county<-poll_county_unclean %>%
    filter(MeasureType=='Average')%>%
    group_by(ReportYear)%>%
    arrange(CountyName)%>%
    arrange(StateName)%>%
    filter(MeasureId==296)%>%
    dplyr::rename(FIPSCode=CountyFips)%>%
    subset(select=c(FIPSCode, ReportYear, Value))%>%
    #Fix Shannon County change to Oglala County SD
    mutate(FIPSCode=gsub("46113","46102", FIPSCode))%>%
    filter(ReportYear==2010)%>%
    subset(select=-c(ReportYear))
  poll_county$FIPSCode<-stri_pad_left(poll_county$FIPSCode, 5, "0")  
  colnames(poll_county) <- c("FIPSCode", "Pollution")
  return(poll_county)
}
```

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Downloading the County Reference Table data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r}
#' Webscrapes and wrangles a table of every US county and its corresponding FIPS code and state name. 
#' Source: https://en.wikipedia.org/wiki/List_of_United_States_counties_and_county_equivalents
#' @Variables: FIPS code, County, State
#' @Year: 2014
#'
#' @return data frame containing every county name and its 
#' corresponding county FIPS code, state FIPS code, and state name.

GetCountyReference <- function(){
  every_us_county <- 
    "https://en.wikipedia.org/wiki/List_of_United_States_counties_and_county_equivalents" %>%
    read_html() %>%
    html_nodes(xpath = '//*[@id="mw-content-text"]/table') %>%
    html_table(fill=TRUE)
  every_us_county2<-every_us_county[[2]]
  every_county<-every_us_county2%>%
    dplyr::rename(FIPSCode=INCITS, County=`County or equivalent`, State=`State or district`)%>%
    subset(select=c( `FIPSCode`, `County`, `State`))
  every_county$FIPSCode<-stri_pad_left(every_county$FIPSCode, 5, "0")
  every_county<-mutate(every_county,StateFips=substr(every_county$FIPSCode,1,2))
  return(every_county)
}
```

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Downloading the USACountyIncomeEmploy data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r}
#' @Variables of interest: Income and IncomeQuartile
#' @Year 2015

#' Scrapes the excel download link for US Income
#' Source: https://www.ers.usda.gov/data-products/county-level-data-sets/county-level-data-sets-download-data.aspx and click Unemployment and median household income for the U.S., States, and counties, 2007-15
#'
#' @return The income dataframe that contains FIPSCode, Income, Unemployment and IncomeQuartile 

GetIncomeData <- function(userName){
  # 
  # #download the data from the URL
  # url <- "https://www.ers.usda.gov/webdocs/DataFiles/CountyLevel_Data_Sets_Download_Data__18026/Unemployment.xls?v=42762"
  # #temporarily store the file
  # tmp <- tempfile(fileext=".xls")
  # download.file(url, destfile=tmp, mode="wb")
  # 
  # income_unclean <- read_excel(tmp, sheet = 1, skip = 7)
  # 
  # #remove the temporary file
  # unlink(tmp)
  
  #------------------
  # Local Download (USDA down)
  # ----------------
  if(userName == "K"){
    path <- "C:\\Users\\kanay\\Documents\\R\\stat133\\AllStates\\"
  }else if(userName == "V"){
    path <- "~/Downloads/stats133data"
  }else if(userName == "A") {
    path <- "/Users/anishakumar/Documents/Stats133/RStudioFiles/Stats133Project/income.xls"
  }else if(userName == "KS"){
    path <- "C:\\Users\\kagex\\Downloads\\income.xls"
  }else{
    path <- "C:\\Users\\Katrlyn\\Downloads\\income.xls"
  }
  
  #
  #
  income_unclean <- read_excel(path, sheet = 1, skip = 7)
  
  #remove any non-alphanumeric characters
  income <- income_unclean %>% 
    mutate(Area_name= gsub(", ..$", "", Area_name), Area_name)%>% #remove any non-alphanumeric characters
    subset(select=c("FIPStxt","Median_Household_Income_2015","Unemployment_rate_2015"))%>% #select for desired variables
    dplyr::rename(FIPSCode=FIPStxt) #Rename FIPStxt so that it is FIPSCode
  
  #Rename the column names 
  colnames(income) <- c("FIPSCode", "Income", "Unemployment")
  
  #Make a column called IncomeQuartile that separates incomes into 4 quartiles
  income$IncomeQuartile <- ntile(income$Income, 4) 
  
  #Name the income levels 
  income$IncomeQuartile[income$IncomeQuartile == 1] <- "< $40k" 
  income$IncomeQuartile[income$IncomeQuartile == 2] <- "$40k - 47k"
  income$IncomeQuartile[income$IncomeQuartile == 3] <- "$47k - 54k"
  income$IncomeQuartile[income$IncomeQuartile == 4] <- "> $54k"
  income$IncomeQuartile <- base::as.factor(income$IncomeQuartile)
  #income$IncomeQuartile = factor(income$IncomeQuartile, levels(income$IncomeQuartile) [c(3,1,2,4)]) #FOR PC
  income$IncomeQuartile <- factor(income$IncomeQuartile, levels = c("< $40k","$40k - 47k","$47k - 54k","> $54k")) #FOR MAC 
  return(income)
}


```


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Downloading the USCountyUrbanForest data 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



The purpose of this document is to extract urban forest from all the counties in the U.S.

```{r}
#' Scrapes the excel download link for each state in the U.S.
#'
#' @return A data frame containing variables: stateNames and downloadLinks (Excel file download links)

Webscrape <- function(){
  #----------------------------------------------
  #Scrape the link to each state from the US data
  #----------------------------------------------
  library(XML)
  library(RCurl)
  library(readxl)
  URL <- "https://www.nrs.fs.fed.us/data/urban/"
  txt <- getURLContent(URL)
  doc <- htmlParse(txt)
  #Scrape the state name
  stateNames <- xpathSApply(doc, '//ul/li/a/strong', xmlValue)
  #Scrape the state link
  stateLinks <- xpathSApply(doc, '//ul[@class="state_list"]/li/a/@href')
  baseURL <- "https://www.nrs.fs.fed.us"
  stateLinks <- paste(baseURL,as.character(stateLinks),sep="")
  #Data Frame of StateName and stateLink
  AllStates <- data.frame(stateNames, stateLinks, stringsAsFactors = FALSE)
  #Fix naming conventions standard Washington DC --> District of Columbia
  AllStates$stateNames[AllStates$stateNames == "Washington, D.C"] <- "District of Columbia"
  #-------------------------------------------------------
  #Scrape the state xls file download link from each state page
  #-------------------------------------------------------
  downloadLinks <- vector(mode="character", length=length(AllStates$stateNames))
  for (i in 1:length(stateLinks)){
    stateURL<- stateLinks[i]
    stateTxt <- getURLContent(stateURL)
    stateDoc <- htmlParse(stateTxt)
    downloadLink <- xpathSApply(stateDoc, '//ol[@id="data_options"]/li/a/@href')
    #The HTML source code is poor so need to use grepl to extract .xls from Xpath results
    length(downloadLink)
    for (j in 1:length(downloadLink)){
       if (grepl(".xls", downloadLink[j])){
        downloadLinks[i] <- downloadLink[j]
        break 
      }
    }
  }
  # Add to dataframe
  AllStates$downloadLinks <- downloadLinks
  # Return only the relevant part of the database
  AllStates <- AllStates %>% select(stateNames, downloadLinks)
  return(AllStates)
}

```

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Support functions for Downloading and loading state Excel files 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r}
#' Creates a reference dataframe that maps county name to FIPS code based on the 2010 census, 
#' with naming updates up to 2015.
#'
#' @param state (optional) to restrict FIPS codes to one state
#' @return A data frame containing variables: State, CountyName, and FIPS (FIPS code)

FIPS_fun <- function(state = NA){
  #Note: colClasses = "character" helps keep the leading 0s
  #http://stackoverflow.com/questions/17414776/read-csv-warning-eof-within-quoted-string-prevents-complete-reading-of-file
  df <- read.table("https://www2.census.gov/geo/docs/reference/codes/files/national_county.txt", sep = ",", col.names = c("State", "StateFIPS", "CountyFIPS", "CountyName", "ClassFIPSCode" ), colClasses = "character", quote = "")
  #Shannon County (46-113) change to Oglala Lakota County (46-102) (Effective 2015)
  df2 <- data.frame(State = "SD", StateFIPS = "46", CountyFIPS = "102", CountyName = "Oglala Lakota County", ClassFIPSCode = "H1")
  df <- rbind(df, df2)
  #Merge state and county into one FIPS code
  FIPS_base <- df %>% mutate(FIPS = paste(StateFIPS, CountyFIPS, sep = ""))
  #Delete Shannon County (It changed to Oglala Lakota)
  FIPS_base <- FIPS_base %>% filter(FIPS != "46113")
  #return FIPS codes of the state passed in
  if(!is.na(state)){
    FIPS_base <- FIPS_base %>% subset(State == state) %>% select(State, CountyName, FIPS)
    return(FIPS_base)
  }else{return(FIPS_base)}
}
```

```{r}
#' Extracts data from an excel file relating to the forestry variables of interest.
#' @Variables: Tree canopy (m2/person), Available green space (ha), and Tree canopy cover in developped regions (%) 
#' for each county in the state. This data, along with the county name and the FIPS code is returned as a data frame.

#' @param file Location of the state .xls file
#' @param stateAbbrev the state postal code for the count of interest
#' @return A data frame containing variables: State, CountyName, FIPS (FIPS code), TreeCanopy, AvailGreenSpace, and TreeCanopyCover

ExtractStateData <- function(file, stateAbbrev){
  # ---------------------------------------------
  # Read-in relevant sheets from the excel files
  # ---------------------------------------------
  if(stateAbbrev == "DC"){
    xl_7 <- read_excel(file, sheet = "5", skip = 3)
    xl_10 <- read_excel(file, sheet = "8", skip = 4) 
  }else{
    xl_7 <- read_excel(file, sheet = "7", skip = 3)
    xl_10 <- read_excel(file, sheet = "10", skip = 3)
  }
  # -----------------------------------
  # Clean and select relevant variables
  # -----------------------------------
  xl_7 <- xl_7 %>% select(c(`X__1`, `m2/person__1`, `Available green space (ha)`))
  #Units: Tree canopy Covering (m2/person), Available green space (ha)
  colnames(xl_7) <- c("CountyName","TreeCanopy", "AvailGreenSpace")
  xl_10 <- xl_10 %>% select(c(`X__1`, `Tree % h`))
  #Tree canopy cover in developped regions (%)
  colnames(xl_10) <- c("CountyName", "TreeCanopyCover")
  #Exclude the variable descriptions at the end of the sheet
  xl_10 <- na.omit(xl_10)
  # --------
  # Join
  # --------
  #Join the two excel sheets to create one datframe of county data
  joined <- full_join(xl_7, xl_10, by = "CountyName")
  #get ride of statewide summary row
  joined_clean <- joined %>% subset(CountyName != "Statewide")
  # ------------------
  # Naming Corrections:
  # -----------------
  # 1) Washington DC must be called District of Columbia to find FIPS code
  # 2) La Salle county in IL changed to LaSalle County in 2001 
  # 3) Clifton Forge city is no longer a county as of 2001
  # 4) Shannon County, SD changed to Oglala Dakota in 2015
  if(stateAbbrev == "DC"){
    #joined_clean[1, "CountyName"] <- "District of Columbia"
    joined_clean$CountyName[joined_clean$CountyName == "Washington, D.C."] <- "District of Columbia"
  }else if(stateAbbrev == "IL"){
    #joined_clean[49,"CountyName"] <- "LaSalle County"
    joined_clean$CountyName[joined_clean$CountyName == "La Salle County"] <- "LaSalle County"
  }else if(stateAbbrev == "VA"){
    joined_clean <- joined_clean %>% filter(CountyName != "Clifton Forge city")
  }else if(stateAbbrev == "SD"){
    joined_clean$CountyName[joined_clean$CountyName == "Shannon County"] <- "Oglala Lakota County"
  }
  # Add FIPS codes to data
  FIPS_base <- FIPS_fun(state = stateAbbrev)
  final_df <- full_join(joined_clean, FIPS_base, by = "CountyName")
  return(final_df)
}

```

To keep from wasting time redownloading files, use this code to download once and use your local files. 
```{r, eval=FALSE}
#' Downloads excel files to a local directory for later extraction and cleaning. Note that the user will need to 
#' manually designate the desired download directory.
#' 
#' @param AllStates data frame that contains stateNames and downloadLinks
#' @return Data frame with stateNames, downloadLinks, and fileLocations 

DownloadLocally <- function(AllStates){
  library(readxl)
  #Stores locations for future file reading
  fileLocations <- vector(mode="character", length=length(AllStates$stateNames))
  #Download file for each state
  for(i in 1:length(AllStates$stateNames)){
    destination <- paste("~/Downloads/stats133data/AllStates/", AllStates$stateNames[i], ".xls", sep = "")
    download.file(AllStates$downloadLinks[i], destfile = destination, mode = "wb" )
    fileLocations[i] <- destination
  }
  AllStates$fileLocations <- fileLocations
  return(AllStates)
}

```

Load the filepaths if you're using the downloaded files
```{r}
#' Loads the locations of all the excel files stored in a local directory for later extraction and cleaning. 
#' Note that the user will need to designate the directory of their downloaded file.
#' 
#' @param AllStates data frame that contains stateNames and downloadLinks
#' @return Data frame with stateNames, downloadLinks, and fileLocations 

LoadFilepaths <- function(AllStates, userName){
  if(userName == "K"){
    AllStates$fileLocations <- paste("C:\\Users\\kanay\\Documents\\R\\stat133\\AllStates\\", AllStates$stateNames, ".xls", sep = "")
  }else if(userName == "V"){
    AllStates$fileLocations <- paste("~/Downloads/stats133data/AllStates/", AllStates$stateNames, ".xls", sep = "")
  }else if(userName == "A") {
    AllStates$fileLocations <- paste("/Users/anishakumar/Documents/Stats133/RStudioFiles/Stats133Project/AllStates/", AllStates$stateNames, ".xls", sep = "")
  }else if(userName == "KS"){
    AllStates$fileLocations <- paste("C:\\Users\\kagex\\stats133Project\\AllStates\\", AllStates$stateNames, ".xls", sep = "")
  }else{
    AllStates$fileLocations <- paste("C:\\Users\\Katrlyn\\stats133Project\\AllStates\\", AllStates$stateNames, ".xls", sep = "")
  }
  return(AllStates)
}

```

------------------------------------------------------
Download Tree Data  (Method 1: Download all the files locally)
------------------------------------------------------
```{r}
#' Scrapes the download link for each state's forestry data and then extracts forestry data for each county.
#' Source: https://www.nrs.fs.fed.us/data/urban/
#' @Variables: Tree canopy (m2/person), Available green space (ha), and Tree canopy cover in developped regions (%) 
#' for each county in the state. This data, along with the county name and the FIPS code is returned as a data frame.
#'
#' @return A data frame containing county name, FIPS code, tree canopy per person, available green space, and 
#' tree canopy cover in developped areas.

GetTreeData <- function(userName){
  #Webscrape the data links from the USDA Forest Service
  #The original data source is: https://www.nrs.fs.fed.us/data/urban/ 
  
  AllStates <- Webscrape()
  
  #Download all the xls files locally for data processing
  #AllStates <- DownloadLocally(AllStates)
  AllStates <- LoadFilepaths(AllStates, userName) #You will need to load this every time if you're working from local files
  
  #Extract urban forestry for each state in the United States
  for(i in 1:length(AllStates$downloadLinks)){
    print(AllStates$stateNames[i])
    #Get the current state postal abbreviation 
    if(AllStates$stateNames[i] == "District of Columbia"){
      stateAbbrev <- "DC"
    }else{
      stateAbbrev <- state.abb[match(AllStates$stateNames[i],state.name)]
    }
    
    #Extract the variables Tree canopy Covering (m2/person), 
    #Available green space (ha), and Tree canopy cover in developped regions (%) for the current state
    state_df <- ExtractStateData(AllStates$fileLocations[i], stateAbbrev)
    
    #Build a data frame of all the states
    if(i == 1){
      df_base <- state_df
    }else if( i == 2){
      df_full <- rbind(df_base, state_df)
    }else{
      df_full <- rbind(df_full, state_df)
    }
  }
  
  #Things that need fixing still
  df <- df_full %>% subset(is.na(FIPS) | is.na(TreeCanopy))
  df
  
  #-------------------------------------------------------------------------------------------
  ###### MY CODE  SO THAT I CAN JOIN THE TREE DATA TO MY OTHER DATA FOR THE SCATTERPLOTS######
  #-------------------------------------------------------------------------------------------
  tree_data<-df_full[, -grep("State|Name", colnames(df_full))]
  #Filter out outlier values?
  tree_data<-tree_data%>%rename(FIPSCode=FIPS)%>%filter(TreeCanopyCover<.55)
  return(tree_data)
}


```


------------------------------------------------------
Download Tree Data (Method 2: Download via temporary files)
------------------------------------------------------


```{r, eval=FALSE}
#' Scrapes the download link for each state's forestry data and then extracts forestry data for each county.
#' Source: https://www.nrs.fs.fed.us/data/urban/
#' @Variables: Tree canopy (m2/person), Available green space (ha), and Tree canopy cover in developped regions (%) 
#' for each county in the state. This data, along with the county name and the FIPS code is returned as a data frame.
#'
#' @return A data frame containing county name, FIPS code, tree canopy per person, available green space, and 
#' tree canopy cover in developped areas.

GetTreeDataTEMP <- function(){

  AllStates <- Webscrape()
  
  #Download via temp files (no local storage on hard drive )
  
  for(i in 1:length(AllStates$downloadLinks)){
    #Download xls file
    url <- AllStates$downloadLinks[i]
    tmp <- tempfile(fileext=".xls")
    download.file(url,destfile=tmp, mode="wb")
    
    #Extract urban forestry for each state in the United States
    print(AllStates$stateNames[i])
    #Get the current state postal abbreviation 
    if(AllStates$stateNames[i] == "District of Columbia"){
      stateAbbrev <- "DC"
    }else{
      stateAbbrev <- state.abb[match(AllStates$stateNames[i],state.name)]
    }
    
    #Extract the variables Tree canopy Covering (m2/person), Available green space (ha), and Tree canopy cover in developped regions (%) for the current state
    state_df <- ExtractStateData(tmp, stateAbbrev)
    
    #Build a data frame of all the states
    if(i == 1){
      df_base <- state_df
    }else if( i == 2){
      df_full <- rbind(df_base, state_df)
    }else{
      df_full <- rbind(df_full, state_df)
    }
    unlink(tmp)
  }
  #Things that need fixing still
  df <- df_full %>% subset(is.na(FIPS) | is.na(TreeCanopy))
  df
  
  #-------------------------------------------------------------------------------------------
  ###### MY CODE  SO THAT I CAN JOIN THE TREE DATA TO MY OTHER DATA FOR THE SCATTERPLOTS######
  #-------------------------------------------------------------------------------------------
  tree_data<-df_full[, -grep("State|Name", colnames(df_full))]
  #Filter out outlier values?
  tree_data<-tree_data%>%rename(FIPSCode=FIPS)%>%filter(TreeCanopyCover<.55)
  return(tree_data)
}

```


```{r}
#Pacific 53, 16, 32, 06, 41 
#SouthWest  35, 04, 49, 40 
#West 30, 38, 46, 49, 56, 08, 31, 20
#SouthEast 05, 22, 01, 47, 28, 12, 37, 45, 21, 13
#MidWest 19, 29, 26, 27, 17, 18, 55, 39
#NorthEast 51, 54, 24, 44, 42, 36, 23, 33, 50, 25, 09, 34, 10, 11

#West 53, 16, 32, 06, 41 
GetStateRegion4 <- function(all_data){
  all_data$Region <- ""
  for (i in 1:nrow(all_data)){
    if (all_data$StateFips[i] %in% c("53", "16", "32", "06", "41", "30", "56", "49", "08", "04", "35")){ #11
      all_data$Region[i]<- "West"
    } else if (all_data$StateFips[i] %in% c("38", "46", "31", "20", "29", "19", "27", "55", "17", "18", "39", "26")){ #12
      all_data$Region[i]<- "MidWest"
    } else if (all_data$StateFips[i] %in% c("40", "48", "22", "05", "28", "01", "12", "13", "47", "45", "37", "21", "51", "54", "24", "10", "11")){ #17
      all_data$Region[i] <- "South"
    } else if (all_data$StateFips[i] %in% c("42", "34", "36", "09", "44", "25", "50", "33", "23")){ #9
      all_data$Region[i] <- "NorthEast"
    } else 
      all_data$Region[i] <- NA
  }
  all_data$Region <- factor(all_data$Region, levels = c("West", "MidWest", "South", "NorthEast"))
  return(all_data)
}

GetStateRegion6 <- function(all_data){
  all_data$Region <- ""
  for (i in 1:nrow(all_data)){
    if (all_data$StateFips[i] %in% c("53", "16", "32", "06", "41", "02")){
      all_data$Region[i]<- "Pacific"
    } else if (all_data$StateFips[i] %in% c("35", "04", "49", "40", "15")){
      all_data$Region[i]<- "SouthWest"
    } else if (all_data$StateFips[i] %in% c("30", "38", "46", "49", "56", "08", "31", "20")){
      all_data$Region[i] <- "West"
    } else if (all_data$StateFips[i] %in% c("05", "22", "01", "47", "28", "12", "37", "45", "21", "13")){
      all_data$Region[i] <- "SouthEast"
    } else if (all_data$StateFips[i] %in% c("19", "29", "26", "27", "17", "18", "55", "39")){
      all_data$Region[i] <- "MidWest"
    } else if (all_data$StateFips[i] %in% c("51", "54", "24", "44", "42", "36", "23", "33", "50", "25", "09", "34", "10", "11")){
      all_data$Region[i] <- "NorthEast"
    } else 
      all_data$Region[i] <- NA
  }
  return(all_data)
}
```



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Main Code: Acquire and Join all data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r}

#-------USER--------
# READ BELOW BEFORE RUNNING
#--------------------
#Put the first initial of your first name.
userName = "A"

all_data=NULL

#Get reference table of counties to FIPS codes
every_county <- GetCountyReference()

#Acquire all data using support functions
edu_data <- GetEduData(userName)
income_data <- GetIncomeData(userName)
poll_data <- GetPollutionData()
tree_data <- GetTreeData(userName)


#Join all data to prepare for visualization
all_data<-plyr::join_all(list(every_county, edu_data, income_data, poll_data, tree_data), by='FIPSCode', type='full')
View(all_data)
all_data <- GetStateRegion4(all_data)

#all_data<-na.omit(all_data)


head(all_data)

save(all_data, file="all_data.RData")

```



