
------------------------------
------------------------------
DATA GATHERING
------------------------------
------------------------------
```{r include=FALSE}
library(DataComputing)
library(RCurl)
library(readxl)
library(mosaic)
library(readr)
library(tidyr) 
library(dplyr)
library(stringi)
library(XML)
library(rvest)
library(rgdal)
```
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
County FIPS Reference Table Data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
```{r}
#' Webscrapes and wrangles a table of every US county and its corresponding FIPS code and state name. 
#' Source: https://en.wikipedia.org/wiki/List_of_United_States_counties_and_county_equivalents
#' @Variables: FIPS code, County, State
#' @Year: 2014
#'
#' @return data frame containing every county name and its 
#' corresponding county FIPS code, state FIPS code, and state name.

GetCountyReference <- function(){
  every_us_county <- 
    "https://en.wikipedia.org/wiki/List_of_United_States_counties_and_county_equivalents" %>%
    read_html() %>%
    html_nodes(xpath = '//*[@id="mw-content-text"]/table') %>%
    html_table(fill=TRUE)
  every_us_county2<-every_us_county[[2]]
  every_county<-every_us_county2%>%
    dplyr::rename(FIPSCode=INCITS, County=`County or equivalent`, State=`State or district`)%>%
    subset(select=c( `FIPSCode`, `County`, `State`))
  every_county$FIPSCode<-stri_pad_left(every_county$FIPSCode, 5, "0")
  every_county<-mutate(every_county,StateFips=substr(every_county$FIPSCode,1,2))
  return(every_county)
}
```
~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Educational Attainment Data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~
```{r}
#' Scrapes the excel download link for US County Education Attainment
#' Source: "https://www.ers.usda.gov/data-products/county-level-data-sets/county-level-data-sets-download-data.aspx" #' (Click Educational attainment for the U.S., States, and counties, 1970-2015)
#' @Variables of interest: Rural-Urban Continuum code and Bachelors (%) 
#' @Year 2013 Rural-Urban Continuum Codes, 2011-2015 Education Attainment
#'
#' @return The edu_data that contains the FIPSCode, UrbanCode (2013 Rural-Urban Continuum Code), LessThanHS (%), HSDiploma (%), Bachelors (%), UrbanRank. 

GetEduData <- function(){
  
  # #Use downoload link to read the data
  url <- "https://www.ers.usda.gov/webdocs/DataFiles/48747/Education.xls?v=42762"
  #tmp is a temporary file in which the data from the excel sheet is stored
  tmp <- tempfile(fileext=".xls")
  download.file(url, destfile=tmp, mode="wb")
  #read data from sheet 1 beginning at row 5
  edu_data_unclean <- read_excel(tmp, sheet = 1, skip = 4)

  #Get rid of the temporary file tmp
  unlink(tmp)
  
  #----Wrangle and select variables----
  
  #Choose the columns from edu_data_clean that has FIPS Code, 2013 Rural-Urban Continuum Code and any columns that have information from 2011
  edu_data<-edu_data_unclean[, grep("2011|FIPS Code|2013 Rural", colnames(edu_data_unclean))] 
  
  #Choose columns from edu_data taht has FIPSCode, 2013 Rural-Urban Continuum Code and Percent
  edu_data<-edu_data[, grep("Percent|FIPS Code|2013 Rural", colnames(edu_data))]
  
  #Rename FIPS Code column to FIPSCode
  edu_data<-edu_data%>%dplyr::rename(FIPSCode=`FIPS Code`)
  
  #Rename the columns so that they are cleaner 
  colnames(edu_data)<-c('FIPSCode', 'UrbanCode', 'LessThanHS', 'HSDiploma', 'SomeCollege','Bachelors')
  
  edu_data$UrbanRank <- ""
  
  #The for loop classifies the UrbanCode (Rural-Urban Continuum Code). 
  #Code 1-3 is metropolitan, 4-7 is urban and 8 - 11 is rural.
  for (i in 1:nrow(edu_data)){
     if (is.na(edu_data$UrbanCode[i])){
       edu_data$UrbanRank[i] <- NA
      } else if (edu_data$UrbanCode[i] <= 3){
        edu_data$UrbanRank[i] <- "Metropolitan"
      } else if (edu_data$UrbanCode[i] <= 7){
        edu_data$UrbanRank[i] <- "Urban"
      } else {
        edu_data$UrbanRank[i] <- "Rural"
      }
  }
  edu_data$UrbanRank <- factor(edu_data$UrbanRank, levels = c("Rural", "Urban", "Metropolitan"))
  return(edu_data)
}
```
---END Educational Attainment Data---

~~~~~~~~~~~~~~~~~~
Air Quality Data
~~~~~~~~~~~~~~~~~~
```{r}
#' Downloads and wrangles pollution data in the form of air quality measurements from the EPA. 
#' Source: https://data.cdc.gov/dataset/Air-Quality-Measures-on-the-National-Environmental/cjae-szjv
#' @Variables: Annual average ambient concentrations of PM2.5 in micrograms per cubic meter 
#' (based on seasonal averages and daily measurement)
#' @Year: 2010
#'
#' @return data frame containing air quality for each county in the united states

GetPollutionData <- function(){
  poll_county_unclean<-read.csv("https://data.cdc.gov/api/views/cjae-szjv/rows.csv?accessType=DOWNLOAD")
  poll_county<-poll_county_unclean %>%
    filter(MeasureType=='Average')%>%
    group_by(ReportYear)%>%
    arrange(CountyName)%>%
    arrange(StateName)%>%
    filter(MeasureId==296)%>%
    dplyr::rename(FIPSCode=CountyFips)%>%
    subset(select=c(FIPSCode, ReportYear, Value))%>%
    #Fix Shannon County change to Oglala County SD
    mutate(FIPSCode=gsub("46113","46102", FIPSCode))%>%
    filter(ReportYear==2010)%>%
    subset(select=-c(ReportYear))
  poll_county$FIPSCode<-stri_pad_left(poll_county$FIPSCode, 5, "0")  
  colnames(poll_county) <- c("FIPSCode", "Pollution")
  return(poll_county)
}
```
---END Air Quality Data---

~~~~~~~~~~~~~
Income Data
~~~~~~~~~~~~~
```{r}
#' Scrapes the excel download link for US Income
#' Source: https://www.ers.usda.gov/data-products/county-level-data-sets/county-level-data-sets-download-data.aspx #' (Unemployment and median household income for the U.S., States, and counties, 2007-15)
#' @Variables of interest: Income and IncomeQuartile
#' @Year 2015
#'
#' @return The income dataframe that contains FIPSCode, Income, Unemployment and IncomeQuartile 

GetIncomeData <- function(){
  url <- "https://www.ers.usda.gov/webdocs/DataFiles/48747/Unemployment.xls?v=42762"
  tmp <- tempfile(fileext=".xls")
  download.file(url, destfile=tmp, mode="wb")

  income_unclean <- read_excel(tmp, sheet = 1, skip = 7)
  unlink(tmp)
  
  #remove any non-alphanumeric characters
  income <- income_unclean %>% 
    mutate(Area_name= gsub(", ..$", "", Area_name), Area_name)%>% #remove any non-alphanumeric characters
    subset(select=c("FIPStxt","Median_Household_Income_2015","Unemployment_rate_2015"))%>% 
    dplyr::rename(FIPSCode=FIPStxt)
  colnames(income) <- c("FIPSCode", "Income", "Unemployment")
  
  #Make a column called IncomeQuartile that separates incomes into 4 quartiles
  income$IncomeQuartile <- ntile(income$Income, 4) 
  
  #Name the income levels 
  income$IncomeQuartile[income$IncomeQuartile == 1] <- "< $40k" 
  income$IncomeQuartile[income$IncomeQuartile == 2] <- "$40k - 47k"
  income$IncomeQuartile[income$IncomeQuartile == 3] <- "$47k - 54k"
  income$IncomeQuartile[income$IncomeQuartile == 4] <- "> $54k"
  income$IncomeQuartile <- base::as.factor(income$IncomeQuartile)
  income$IncomeQuartile <- factor(income$IncomeQuartile, levels = c("< $40k","$40k - 47k","$47k - 54k","> $54k")) 
  return(income)
}
```
----END Income Data-----

~~~~~~~~~~~~~~~~~~~
Forestry Data 
~~~~~~~~~~~~~~~~~~~
```{r}
#' Scrapes the excel download link for each state in the U.S.
#'
#' @return A data frame containing variables: stateNames and downloadLinks (Excel file download links)

Webscrape <- function(){
  #----------------------------------------------
  #Scrape the link to each state from the US data
  #----------------------------------------------
  library(XML)
  library(RCurl)
  library(readxl)
  URL <- "https://www.nrs.fs.fed.us/data/urban/"
  txt <- getURLContent(URL)
  doc <- htmlParse(txt)
  #Scrape the state name
  stateNames <- xpathSApply(doc, '//ul/li/a/strong', xmlValue)
  #Scrape the state link
  stateLinks <- xpathSApply(doc, '//ul[@class="state_list"]/li/a/@href')
  baseURL <- "https://www.nrs.fs.fed.us"
  stateLinks <- paste(baseURL,as.character(stateLinks),sep="")
  #Data Frame of StateName and stateLink
  AllStates <- data.frame(stateNames, stateLinks, stringsAsFactors = FALSE)
  #Fix naming conventions standard Washington DC --> District of Columbia
  AllStates$stateNames[AllStates$stateNames == "Washington, D.C"] <- "District of Columbia"
  #-------------------------------------------------------
  #Scrape the state xls file download link from each state page
  #-------------------------------------------------------
  downloadLinks <- vector(mode="character", length=length(AllStates$stateNames))
  for (i in 1:length(stateLinks)){
    stateURL<- stateLinks[i]
    stateTxt <- getURLContent(stateURL)
    stateDoc <- htmlParse(stateTxt)
    downloadLink <- xpathSApply(stateDoc, '//ol[@id="data_options"]/li/a/@href')
    #The HTML source code is poor so need to use grepl to extract .xls from Xpath results
    length(downloadLink)
    for (j in 1:length(downloadLink)){
       if (grepl(".xls", downloadLink[j])){
        downloadLinks[i] <- downloadLink[j]
        break 
      }
    }
  }
  # Add to dataframe
  AllStates$downloadLinks <- downloadLinks
  # Return only the relevant part of the database
  AllStates <- AllStates %>% select(stateNames, downloadLinks)
  return(AllStates)
}

```

```{r}
#' Creates a reference dataframe that maps county name to FIPS code based on the 2010 census, 
#' with naming updates up to 2015.
#'
#' @param state (optional) to restrict FIPS codes to one state
#' @return A data frame containing variables: State, CountyName, and FIPS (FIPS code)

FIPS_fun <- function(state = NA){

  df <- read.table("https://www2.census.gov/geo/docs/reference/codes/files/national_county.txt", sep = ",", col.names = c("State", "StateFIPS", "CountyFIPS", "CountyName", "ClassFIPSCode" ), colClasses = "character", quote = "")
  #Shannon County (46-113) change to Oglala Lakota County (46-102) (Effective 2015)
  df2 <- data.frame(State = "SD", StateFIPS = "46", CountyFIPS = "102", CountyName = "Oglala Lakota County", ClassFIPSCode = "H1")
  df <- rbind(df, df2)
  #Merge state and county into one FIPS code
  FIPS_base <- df %>% mutate(FIPS = paste(StateFIPS, CountyFIPS, sep = ""))
  #Delete Shannon County (It changed to Oglala Lakota)
  FIPS_base <- FIPS_base %>% filter(FIPS != "46113")
  #return FIPS codes of the state passed in
  if(!is.na(state)){
    FIPS_base <- FIPS_base %>% subset(State == state) %>% select(State, CountyName, FIPS)
    return(FIPS_base)
  }else{return(FIPS_base)}
}
```

```{r}
#' Extracts data from an excel file relating to the forestry variables of interest.
#' @Variables: Tree canopy (m2/person), Available green space (ha), and Tree canopy cover in developed regions (%) 
#' @param file Location of the state .xls file
#' @param stateAbbrev the state postal code for the count of interest
#' @return A data frame containing variables: State, CountyName, FIPS (FIPS code), TreeCanopy, AvailGreenSpace, and TreeCanopyCover

ExtractStateData <- function(file, stateAbbrev){
  # ---------------------------------------------
  # Read-in relevant sheets from the excel files
  # ---------------------------------------------
  if(stateAbbrev == "DC"){
    xl_7 <- read_excel(file, sheet = "5", skip = 3)
    xl_10 <- read_excel(file, sheet = "8", skip = 4) 
  }else{
    xl_7 <- read_excel(file, sheet = "7", skip = 3)
    xl_10 <- read_excel(file, sheet = "10", skip = 3)
  }
  # -----------------------------------
  # Clean and select relevant variables
  # -----------------------------------
  xl_7 <- xl_7 %>% select(c(`X__1`, `m2/person__1`, `Available green space (ha)`))
  #Units: Tree canopy Covering (m2/person), Available green space (ha)
  colnames(xl_7) <- c("CountyName","TreeCanopy", "AvailGreenSpace")
  xl_10 <- xl_10 %>% select(c(`X__1`, `Tree % h`))
  #Tree canopy cover in developed regions (%)
  colnames(xl_10) <- c("CountyName", "TreeCanopyCover")
  #Exclude the variable descriptions at the end of the sheet
  xl_10 <- na.omit(xl_10)
  # --------
  # Join
  # --------
  #Join the two excel sheets to create one datframe of county data
  joined <- full_join(xl_7, xl_10, by = "CountyName")
  #get ride of statewide summary row
  joined_clean <- joined %>% subset(CountyName != "Statewide")
  # ------------------
  # Naming Corrections:
  # -----------------
  # 1) Washington DC must be called District of Columbia to find FIPS code
  # 2) La Salle county in IL changed to LaSalle County in 2001 
  # 3) Clifton Forge city is no longer a county as of 2001
  # 4) Shannon County, SD changed to Oglala Dakota in 2015
  if(stateAbbrev == "DC"){
    #joined_clean[1, "CountyName"] <- "District of Columbia"
    joined_clean$CountyName[joined_clean$CountyName == "Washington, D.C."] <- "District of Columbia"
  }else if(stateAbbrev == "IL"){
    #joined_clean[49,"CountyName"] <- "LaSalle County"
    joined_clean$CountyName[joined_clean$CountyName == "La Salle County"] <- "LaSalle County"
  }else if(stateAbbrev == "VA"){
    joined_clean <- joined_clean %>% filter(CountyName != "Clifton Forge city")
  }else if(stateAbbrev == "SD"){
    joined_clean$CountyName[joined_clean$CountyName == "Shannon County"] <- "Oglala Lakota County"
  }
  # Add FIPS codes to data
  FIPS_base <- FIPS_fun(state = stateAbbrev)
  final_df <- full_join(joined_clean, FIPS_base, by = "CountyName")
  return(final_df)
}
```

```{r}
#' Scrapes the download link for each state's forestry data and then extracts forestry data for each county.
#' Source: https://www.nrs.fs.fed.us/data/urban/
#' @Variables: Tree canopy (m2/person), Available green space (ha), and Tree canopy cover in developed regions (%) 
#'
#' @return A data frame containing county name, FIPS code, tree canopy per person, available green space, and 
#' tree canopy cover in developed areas.

GetTreeData <- function(){
  AllStates <- Webscrape()
  #Download via temp files (no local storage on hard drive )
  for(i in 1:length(AllStates$downloadLinks)){
    url <- AllStates$downloadLinks[i]
    tmp <- tempfile(fileext=".xls")
    download.file(url,destfile=tmp, mode="wb")
    
    #Extract urban forestry for each state in the United States
    print(AllStates$stateNames[i])
    #Get the current state postal abbreviation 
    if(AllStates$stateNames[i] == "District of Columbia"){
      stateAbbrev <- "DC"
    }else{
      stateAbbrev <- state.abb[match(AllStates$stateNames[i],state.name)]
    }
    
    #Extract the variables Tree canopy Covering (m2/person), Available green space (ha), and Tree canopy cover in developed regions (%) for the current state
    state_df <- ExtractStateData(tmp, stateAbbrev)
    
    #Build a data frame of all the states
    if(i == 1){
      df_base <- state_df
    }else if( i == 2){
      df_full <- rbind(df_base, state_df)
    }else{
      df_full <- rbind(df_full, state_df)
    }
    unlink(tmp)
  }
  #Drop everything except for the variables of interest and FIPS code
  tree_data<-df_full[, -grep("State|Name", colnames(df_full))]
  #name to faciliate later join
  tree_data<-tree_data%>%rename(FIPSCode=FIPS)
  return(tree_data)
}
```
----END Forestry Data------

-------------
Arsenic Data
-------------
```{r}
#' Downloads Arsenic water quality data from USGS 
#' Source: https://water.usgs.gov/nawqa/trace/data/index.html#ARSENIC_NOV01
#' @Year:  1973 - 2001
#' @Variables: State name,FIPS code, arsenic conentraions, lat and long
#'
#' @return data frame containing variables of interest

downloadArsenic <- function(){
  url <- "https://water.usgs.gov/nawqa/trace/data/arsenic_nov2001.xls"
  tmp <- tempfile(fileext=".xls")
  download.file(url,destfile=tmp, mode="wb")
  arsenic <- read_excel(tmp, skip=58)
  # ----DATA CLEANING----
  # get rid of non-continental US data (Alaska, Puerto Rico, Virgin Islands)
  arsenic <- arsenic[!arsenic$STATE %in% c("AK","PR","VI"),]
  # only keep columns we need (especially becuase a few of the unnecessary columns loaded in really weird)
  # columns needed: state, fips code, arsenic concentration, latitude & longitude
  arsenic <- arsenic %>%
    dplyr::select(STATE,FIPS,AS_CONC,LAT_DD,LON_DD)
  # many numeric data is in character form--change from character to numeric
  arsenic$LAT_DD <- as.numeric(arsenic$LAT_DD)
  arsenic$LON_DD <- as.numeric(arsenic$LON_DD)
  arsenic$AS_CONC <- as.numeric(arsenic$AS_CONC)
  arsenic$FIPS <- as.numeric(arsenic$FIPS)
  # take out any observations with incomplete data (eg. missing fips or arsenic)
  arsenic <- arsenic[complete.cases(arsenic[,2]),]
  return(arsenic)
}

```

```{r}
#' Interpolates arsenic data using invered distance weighted model
#' @param arsenic downloaded data frame including point data from field stations
#'
#' @return spatial data frame of interpolated data for  every ~0.25 sq mi of the US

Interpolate <- function(arsenic){
  us.map <- GetCountyShapefile()
  ## PREPPIND DATA FOR INTERPOLATION
  ## duplicate cleaned arsenic data to prevent overwriting
  arsenic_test <- arsenic
  ## assign coordinates--LON must be multiplied by negative to reflect that it is located in the W. Hemisphere
  ## if not, this will plot on a mirrored image of the US
  arsenic_test$x <- -1*arsenic_test$LON_DD
  arsenic_test$y <- arsenic_test$LAT_DD
  ## this makes arsenic_test into a spatial data
  coordinates(arsenic_test) = ~x + y
  plot(arsenic_test)
  ## define the projection for arsenic_test to match the projection for us.map
  proj4string(arsenic_test) <- proj4string(us.map)
  ## setting the interpolation area
  ## basically the 4 most outer points of us.map in terms of longitude and latitude
  x.range <- as.numeric(c(-125, -66))  # min/max longitude of the interpolation area
  y.range <- as.numeric(c(24, 50))  # min/max latitude of the interpolation area
  ## this creates the interpolation grid
  ## it specifies the interpolatino area, and the resolution--in this case 0.1 deg. lon. x 0.1 deg. lat.
  grd <- expand.grid(x = seq(from = x.range[1], to = x.range[2], by = 0.1), y = seq(from = y.range[1], to = y.range[2], by = 0.1))
  coordinates(grd) <- ~x + y # define spatial coordinates of grd
  proj4string(grd) <- proj4string(us.map) #with the same projections
  gridded(grd) <- TRUE
  ## visualization of grid and arsenic data
  plot(grd, cex = 1.5, col = "grey")
  points(arsenic_test, pch = 1, col = "red", cex = 1)
  ## perform the interpolation! (this will take ~20min)
  idw <- krige(AS_CONC ~ 1, arsenic_test, grd)
  return(idw)
}
```


```{r}
#' Summarizing the interpolated data to find average arsenic concentration per county
#' @param idw spatial data frame of interpolated data
#'
#' @return data frame of FIPSCode, arsenic values, and discrete values of arsenic

ArsenicbyCounty <- function(idw){
  library(raster)
  us.map <- GetCountyShapefile()
  ## convert results of interpolation from spatial pixel data to spatial raster data
  idw_raster <- raster(idw)
  ## take the mean raster value (= arsenic concentrations) within the bounds of each county defined by us.map
  avgArsenic <- extract(idw_raster, us.map, fun = mean, sp=TRUE)
  ## convert results to data frame for data manipulation
  avgArsenic_df <- as.data.frame(avgArsenic)
  avgArsenic_df$arsenic_discrete <- NULL
  avgArsenic_df$arsenic_discrete[avgArsenic_df$var1.pred < 3] <- "0-3"
  avgArsenic_df$arsenic_discrete[avgArsenic_df$var1.pred >= 3 & avgArsenic_df$var1.pred < 5] <- "3-5"
  avgArsenic_df$arsenic_discrete[avgArsenic_df$var1.pred >= 5 & avgArsenic_df$var1.pred < 10] <- "5-10"
  avgArsenic_df$arsenic_discrete[avgArsenic_df$var1.pred >= 10 & avgArsenic_df$var1.pred < 20] <- "10-20"
  avgArsenic_df$arsenic_discrete[avgArsenic_df$var1.pred >= 20] <- "20+"
  avgArsenic_df$arsenic_discrete <- base::as.factor(avgArsenic_df$arsenic_discrete)
  avgArsenic_df$arsenic_discrete = factor(avgArsenic_df$arsenic_discrete, levels(avgArsenic_df$arsenic_discrete) [c(1,4,5,2,3)])
  arsenic_df <- avgArsenic_df %>%
    dplyr::select(GEOID, var1.pred, arsenic_discrete)
  names(arsenic_df) <- c("FIPSCode","arsenic","arsenic_discrete")
  save(arsenic_df, file = "arsenic_df.RData")
  return(arsenic_df)
}
```

-----------------
Main Arsenic code
-----------------
```{r}
#' Downloads, interpolates, ans summarises Arsenic water quality data from USGS 
#' Source: https://water.usgs.gov/nawqa/trace/data/index.html#ARSENIC_NOV01
#' @Year:  1973 - 2001
#' @Variables: FIPS code, arsenic conentraions, latitude, longitude
#'
#' @return data frame containing FIPS code, arsenic conentraions, and discrete arsenic range

GetArsenicData <- function(){
  arsenic <- downloadArsenic()
  idw <- Interpolate(arsenic)
  arsenic_df <- ArsenicbyCounty(idw)
  return(arsenic_df)
}
```

------END Arsenic Data---------

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
****Acquire and Join all data****
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r}
#' Main code to aquire and join all data into the aggregate dataset including data for education, income, pollution, and forestry

all_data=NULL
#Get reference table of counties to FIPS codes
every_county <- GetCountyReference()
#Acquire all data using support functions
edu_data <- GetEduData()
income_data <- GetIncomeData()
poll_data <- GetPollutionData()
tree_data <- GetTreeData()
arsenic_data <- GetArsenicData()
#Join all data to prepare for visualization
all_data<-plyr::join_all(list(every_county, edu_data, income_data, poll_data, tree_data, arsenic_data), by='FIPSCode', type='full')
```

------------------------------
------------------------------
DATA VISUALIZATION
------------------------------
------------------------------
```{r include=FALSE}
library(DataComputing)
library(readr)
library(rgdal)
library(sp)
library(rgeos)
library(rgdal)
library(maptools)
library(dplyr)
library(leaflet)
library(scales)
library(tigris)
library(mapproj)
library(ggplot2)
```
---------------------------
Shapefile for Visualization
---------------------------
```{r}
#' Downloads and loads the county-level simplified geographic boundary shapefile from the US Census Shapefiles.
#' Source: https://www.census.gov/geo/maps-data/data/cbf/cbf_counties.html
#' @Year: 2015
#'
#' @return spatial data frame of county-level geographic boundaries
GetCountyShapefile <- function(){
  library(tigris)
  # Download county shape file from US Census using streamlined TIGRIS package. 
  us.map <- tigris::counties(cb = TRUE, year = 2015)
  # ----Clean county shapefile----
  # Remove Alaska(2), Hawaii(15), Puerto Rico (72), Guam (66), Virgin Islands (78), American Samoa (60)
  # Mariana Islands (69), Micronesia (64), Marshall Islands (68), Palau (70), Minor Islands (74)
  us.map <- us.map[!us.map$STATEFP %in% c("02", "15", "72", "66", "78", "60", "69",
                                          "64", "68", "70", "74"),]
  # Make sure other outling islands are removed.
  us.map <- us.map[!us.map$STATEFP %in% c("81", "84", "86", "87", "89", "71", "76",
                                          "95", "79"),]
  return(us.map)  
}

```
---------------------------------------
Education (Bachelors map) Leaflet Plot
---------------------------------------
```{r, echo=FALSE}
countyShapefile <- GetCountyShapefile()
small_data <- all_data %>% 
  select(FIPSCode, Bachelors)
# Merge spatial df with air quality data.
counties <- geo_join(countyShapefile, small_data, "GEOID", "FIPSCode", how = "left")
# Format popup data for leaflet map.
popup_dat <- paste(sep = "<br/>",
  "<b>County: </b>", 
  counties$NAME, 
  "<b>Value: </b>", 
  counties$Bachelors)
#Let leaflet calculate the colors and labels for you 
pal <- colorNumeric(
  palette =  "YlGnBu",
  domain = counties$Bachelors
)
# Render Map
map <- leaflet(counties, width="100%") %>% addTiles()
education_map <- map %>% 
  addPolygons(stroke = TRUE, color = "white", weight = .1, smoothFactor = 0.5, opacity = 1, 
    fillColor = ~pal(Bachelors), fillOpacity = 1, popup = popup_dat, 
    highlight = highlightOptions(color = "#666", weight = 2, bringToFront = TRUE)) %>%
  addLegend("bottomright", pal = pal, values = ~Bachelors,
    title = "Population with<br>Bachelor's Degree<br>or Higher",
    labFormat = labelFormat(suffix = "%"), na.label = "county missing data",
    opacity = 1)

education_map

library(htmlwidgets)
saveWidget(education_map, file="education_map.html", selfcontained = FALSE)
```

------------------------------------------------
Air quality (Particulate matter) Leaflet Plot
------------------------------------------------
```{r, echo=FALSE}
countyShapefile <- GetCountyShapefile()
small_data <- all_data %>% 
  select(FIPSCode, Pollution)
#Merge spatial df with air quality data.
counties <- geo_join(countyShapefile, small_data, "GEOID", "FIPSCode", how = "left")
# Format popup data for leaflet map.
popup_dat <- paste(sep = "<br/>",
  "<b>County: </b>", 
  counties$NAME, 
  "<b>Value: </b>", 
  counties$Pollution)
#Let leaflet calculate the colors and labels for you 
pal <- colorNumeric(
  palette =  "YlGnBu",
  domain = counties$Pollution
)
# Render Map
map <- leaflet(counties, width="100%") %>% addTiles()
pollution_map <- map %>% 
  addPolygons(stroke = TRUE, color = "white", weight = .1, smoothFactor = 0.5, opacity = 1, 
    fillColor = ~pal(Pollution), fillOpacity = 1, popup = popup_dat, 
    highlight = highlightOptions(color = "#666", weight = 2, bringToFront = TRUE), group = "Pollution") %>%
  addLegend("bottomright", pal = pal, values = ~Pollution,
    title = "Pollution Data",
    labFormat = labelFormat(suffix = "µg/m³"), na.label = "county data missing",
    opacity = 1) 

pollution_map

library(htmlwidgets)
saveWidget(pollution_map, file="pollution_map.html", selfcontained = FALSE)
```

-----------------------------
AvailGreenSpace Leaflet Plot
-----------------------------
```{r, echo=FALSE}
countyShapefile <- GetCountyShapefile()
small_data <- all_data %>% 
  select(FIPSCode, AvailGreenSpace)
#Merge spatial df with air quality data.
counties <- geo_join(countyShapefile, small_data, "GEOID", "FIPSCode", how = "left")
# Format popup data for leaflet map.
popup_dat <- paste(sep = "<br/>",
  "<b>County: </b>", 
  counties$NAME, 
  "<b>Value: </b>", 
  counties$AvailGreenSpace)
#Let leaflet calculate the colors and labels for you 
pal <- colorNumeric(
  palette =  "YlGnBu",
  domain = counties$AvailGreenSpace
)
# Render Map
map <- leaflet(counties, width="100%") %>% addTiles()
availGreenSpace_map <- map %>% 
  addPolygons(stroke = TRUE, color = "white", weight = .1, smoothFactor = 0.5, opacity = 1, 
    fillColor = ~pal(AvailGreenSpace), fillOpacity = 1, popup = popup_dat, 
    highlight = highlightOptions(color = "#666", weight = 2, bringToFront = TRUE)) %>%
  addLegend("bottomright", pal = pal, values = ~AvailGreenSpace,
    title = "Available Green Space",
    labFormat = labelFormat(suffix = "hectare"), na.label = "county data missing",
    opacity = 1)

availGreenSpace_map

library(htmlwidgets)
saveWidget(availGreenSpace_map, file="availGreenSpace_map.html", selfcontained = FALSE)
```

----------------------------------------------------
Tree Canopy Cover in developed regions Leaflet Plot
----------------------------------------------------
```{r, echo=FALSE}
countyShapefile <- GetCountyShapefile()
small_data <- all_data %>% 
  select(FIPSCode, TreeCanopyCover)
#Filter out outlier values
small_data<-small_data%>%filter(TreeCanopyCover<.55)
#Merge spatial df with air quality data.
counties <- geo_join(countyShapefile, small_data, "GEOID", "FIPSCode", how = "left")
# Format popup data for leaflet map.
popup_dat <- paste(sep = "<br/>",
  "<b>County: </b>", 
  counties$NAME, 
  "<b>Value: </b>", 
  counties$TreeCanopyCover)
#Let leaflet calculate the colors and labels for you 
pal <- colorNumeric(
  palette =  "YlGnBu",
  domain = counties$TreeCanopyCover
)
# Render Map
map <- leaflet(counties, width="100%") %>% addTiles()
treeCanopyDeveloped_map <- map %>% 
  addPolygons(stroke = TRUE, color = "white", weight = .1, smoothFactor = 0.5, opacity = 1, 
    fillColor = ~pal(TreeCanopyCover), fillOpacity = 1, popup = popup_dat, 
    highlight = highlightOptions(color = "#666", weight = 2, bringToFront = TRUE)) %>%
  addLegend("bottomright", pal = pal, values = ~TreeCanopyCover,
    title = "Tree canopy cover in developed regions",
    labFormat = labelFormat(suffix = "%"), na.label = ">0.55%",
    opacity = 1)
treeCanopyDeveloped_map
library(htmlwidgets)
saveWidget(treeCanopyDeveloped_map, file="treeCanopyDeveloped_map.html", selfcontained = FALSE)
```

-----------------
Arsenic (ggplot)
-----------------
```{r, eval = FALSE}
#Get county geographic boundaries
us.map <- GetCountyShapefile()
#Converting shapefile to dataframe for visualization
library(broom)
county_map <- tidy(us.map, region="GEOID")
small_data <- arsenic
#Merge spatial df with 
counties <- left_join(county_map, arsenic, by = c("id" = "FIPSCode"))
counties %>%
  ggplot() +
    #blank county map
    geom_polygon(aes(x=long, y=lat, group=group), fill = "white", color="black", size=0.25) +
    #Arsenic data
    geom_polygon(aes(x=long, y=lat, group=group, fill = counties$arsenic_discrete), color="black", size=0.25) +
    ggplot2::coord_map() +
    scale_fill_brewer(palette = "RdYlGn", direction = -1)  +
    labs(title="Arsenic Levels in drinking water (ug/L)") + 
    theme_bw() +
    theme(plot.title=element_text(hjust=0.5),
          axis.line=element_blank(),
          axis.text.x=element_blank(),
          axis.text.y=element_blank(),
          axis.ticks=element_blank(),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank(),
          legend.title=element_blank())
```

~~~~~~~~~~~~~~
Scatter Plots
~~~~~~~~~~~~~~
```{r}
library(ggplot2)
#Plots percent of adults with a Bachelor's degree vs. amount of PM 2.5 (pollution), facetted by income
bach_vs_pollution_lm_income <- all_data %>%
  na.omit() %>%
  ggplot(aes(Pollution, Bachelors)) +
  geom_point(aes(color = IncomeQuartile), alpha = 0.7, size = 2, show.legend = FALSE) +
  scale_color_manual(values = c("#a1d99b","#41ab5d","#238b45","#005a32")) +
  geom_smooth(method = "lm",  fill = "black", col = "black") +
  facet_grid(~ IncomeQuartile) +
  labs(x="Concentration of PM 2.5 (ug/m^3)", y="% Adults with Bachelor's Degrees") +
  xlim(5, 15) +
  theme_bw()

bach_vs_pollution_lm_income

#Plots percent of adults with a Bachelor's degree vs. percent of tree canopy cover, facetted by income
bach_vs_tree_lm_income <- all_data %>% 
  na.omit() %>%
  filter(TreeCanopyCover<.55) %>%  #Filter out outlier values
  ggplot(aes(TreeCanopyCover, Bachelors)) +
  geom_point(aes(color = IncomeQuartile), alpha = 0.7, size = 2, show.legend = FALSE) +
  scale_color_manual(values = c("#a1d99b","#41ab5d","#238b45","#005a32")) +
  geom_smooth(method = "lm",  fill = "black", col = "black") +
  facet_grid(. ~ IncomeQuartile) +
  labs(x="% Tree Canopy Cover", y="% Adults with Bachelor's Degrees") +
  theme_bw() 

bach_vs_tree_lm_income
#Plots percent of adults with a Bachelor's degree vs. amount of PM 2.5 (pollution), facetted by rural-urban classification 
bach_vs_pollution_lm <- all_data %>%
  na.omit() %>%
  ggplot(aes(Pollution, Bachelors)) +
  geom_point(aes(color = UrbanRank), alpha = 0.7, size = 2, show.legend = FALSE) +
   scale_color_manual(values = c("#8dd3c7","#80b1d3","#bc80bd")) +
  geom_smooth(method = "lm", fill = "black", col = "black") +
  facet_grid(~ UrbanRank) +
  labs(x="Concentration of PM 2.5 (ug/m^3)", y="% Adults with Bachelor's Degrees") +
  theme_bw()

bach_vs_pollution_lm

#Plots percent of adults with a Bachelor's degree vs. percent of tree canopy cover, facetted by rural-urban classification 
bach_vs_tree_lm <- all_data %>% 
  na.omit() %>%
  filter(TreeCanopyCover<.55) %>%    #Filter out outlier values
  ggplot(aes(TreeCanopyCover, Bachelors)) +
  geom_point(aes(color = UrbanRank), alpha = 0.7, size = 2, show.legend = FALSE) +
  scale_color_manual(values = c("#8dd3c7","#80b1d3","#bc80bd")) +
  geom_smooth(method = "lm",  fill = "black", col = "black") +
  facet_grid(. ~ UrbanRank) +
  labs(x="% Tree Canopy Cover", y="% Adults with Bachelor's Degrees") +
  theme_bw() 

bach_vs_tree_lm 

#Plots Arsenic concentration vs. Bachelor's degree attainment, facetted by urban rank.
bach_vs_arsenic_lm <- all_data %>%
  na.omit() %>%
  ggplot(aes(arsenic, Bachelors)) +
  geom_point(aes(color = UrbanRank), alpha = 0.3, size = 2) +
  scale_color_manual(values = c("#6baed6","#4292c6","#2171b5")) +
  geom_smooth(method = "lm") +
  facet_grid(~ UrbanRank) +
  labs(x="Arsenic in Drinking Water (ug/L)", y="% Adults with Bachelor's Degrees") +
  theme_bw()

bach_vs_arsenic_lm

#Plots percent of adults with a Bachelor's degree vs. available green space, facetted by rural-urban classification 
bach_vs_green_lm <- all_data %>% 
  na.omit() %>%
  filter(AvailGreenSpace < 10^6) %>% #filter outlier values
  mutate(AvailGreenSpace = AvailGreenSpace/100000) %>%
  ggplot(aes(AvailGreenSpace, Bachelors)) +
  geom_point(aes(color = UrbanRank), alpha = 0.7, size = 2, show.legend = FALSE) +
  scale_color_manual(values = c("#8dd3c7","#80b1d3","#bc80bd")) +
  geom_smooth(method = "lm",  fill = "black", col = "black") +
  facet_grid(. ~ UrbanRank) +
  labs(x="Available Green Space (100,000 ha)", y="% Adults with Bachelor's Degrees") +
  theme_bw() 

bach_vs_green_lm 
```

------------------
------------------
Linear Regressions
------------------
------------------
```{r eval = FALSE}
library(statisticalModeling)
library(rpart)
library(rpart.plot)
library(stats)
library(mosaicData)

#Tree/education regression
et1<-lm(Bachelors~TreeCanopyCover, data=all_data)
et2<-lm(Bachelors~TreeCanopyCover + UrbanCode, data=all_data)
et3<-lm(Bachelors~TreeCanopyCover + UrbanCode + Income, data=all_data)
stargazer::stargazer(et1, et2, et3, type="text",
 dep.var.labels=c("Percent of Adults with Bachelor's Deegree"),
 covariate.labels=c("Tree Canopy Cover","Urban Rank", "Median Income"), out="tree_edu.txt")

#pollution/education regressions
ep1<-lm(Bachelors~Pollution, data=all_data) 
ep2<-lm(Bachelors~Pollution + UrbanCode, data=all_data)
ep3<-lm(Bachelors~Pollution + UrbanCode + Income, data=all_data) 
stargazer::stargazer(ep1, ep2, type="text",
 dep.var.labels=c("Percent of Adults with Bachelor's Deegree"),
 covariate.labels=c("Particulate Matter","Urban Rank", "Median Income"), out="polution_edu.txt")

#green space/education regression
gs1<-lm(Bachelors~AvailGreenSpace, data=filter(all_data, AvailGreenSpace < 10^6)%>%na.omit(all_data))
gs2<-lm(Bachelors~AvailGreenSpace + UrbanCode, data=filter(all_data, AvailGreenSpace < 10^6)%>%na.omit(all_data))
gs3<-lm(Bachelors~AvailGreenSpace + UrbanCode + Income, data=filter(all_data, AvailGreenSpace < 10^6)%>%na.omit(all_data))
stargazer::stargazer(gs1, gs2, gs3, type="text",
 dep.var.labels=c("Percent of Adults with Bachelor's Degree"),
 covariate.labels=c("Available Green Space","Urban Rank", "Median Income"), out="green_edu.txt")

#Arsenic/education reg
ea1<-lm(Bachelors~arsenic, data=all_data)
ea2<-lm(Bachelors~arsenic +UrbanRank, data=all_data)
ea3<-lm(Bachelors~arsenic +Income, data=all_data)
stargazer::stargazer(ea1, ea2, ea3, type="text",
 dep.var.labels=c("Percentage of Adults with Bachelor's Degrees"),
 covariate.labels=c("Arsenic Level","Urban/Rural Classification","Median Income"), out="arsenic_edu.txt")
```
